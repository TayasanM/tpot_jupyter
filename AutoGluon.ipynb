{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d15aa19-b470-4a7d-84f4-b2638757e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251217_084812\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #7-Ubuntu SMP PREEMPT_DYNAMIC Sat Oct 18 10:10:29 UTC 2025\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.7.1+cu126\n",
      "CUDA Version:       12.6\n",
      "GPU Count:          1\n",
      "Memory Avail:       58.46 GB / 61.55 GB (95.0%)\n",
      "Disk Space Avail:   836.52 GB / 914.78 GB (91.4%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: (array([0, 1]), array([4993, 4933]))\n",
      "Test labels : (array([0, 1]), array([1212, 1271]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name              | Type                         | Params | Mode  | FLOPs\n",
      "-----------------------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 108 M  | train | 0    \n",
      "1 | validation_metric | BinaryAUROC                  | 0      | train | 0    \n",
      "2 | loss_func         | CrossEntropyLoss             | 0      | train | 0    \n",
      "-----------------------------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.573   Total estimated model params size (MB)\n",
      "229       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 34: 'val_roc_auc' reached 0.65674 (best 0.65674), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=0-step=34.ckpt' as top 3\n",
      "Epoch 0, global step 69: 'val_roc_auc' reached 0.69541 (best 0.69541), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=0-step=69.ckpt' as top 3\n",
      "Epoch 1, global step 104: 'val_roc_auc' reached 0.71421 (best 0.71421), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=1-step=104.ckpt' as top 3\n",
      "Epoch 1, global step 139: 'val_roc_auc' reached 0.72140 (best 0.72140), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=1-step=139.ckpt' as top 3\n",
      "Epoch 2, global step 174: 'val_roc_auc' reached 0.73469 (best 0.73469), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=2-step=174.ckpt' as top 3\n",
      "Epoch 2, global step 209: 'val_roc_auc' reached 0.72784 (best 0.73469), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=2-step=209.ckpt' as top 3\n",
      "Epoch 3, global step 244: 'val_roc_auc' reached 0.74446 (best 0.74446), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=3-step=244.ckpt' as top 3\n",
      "Epoch 3, global step 279: 'val_roc_auc' reached 0.75020 (best 0.75020), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=3-step=279.ckpt' as top 3\n",
      "Epoch 4, global step 314: 'val_roc_auc' reached 0.74540 (best 0.75020), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812/epoch=4-step=314.ckpt' as top 3\n",
      "Epoch 4, global step 349: 'val_roc_auc' was not in top 3\n",
      "Epoch 5, global step 384: 'val_roc_auc' was not in top 3\n",
      "Epoch 5, global step 419: 'val_roc_auc' was not in top 3\n",
      "Epoch 6, global step 454: 'val_roc_auc' was not in top 3\n",
      "Epoch 6, global step 489: 'val_roc_auc' was not in top 3\n",
      "Epoch 7, global step 524: 'val_roc_auc' was not in top 3\n",
      "Epoch 7, global step 559: 'val_roc_auc' was not in top 3\n",
      "Epoch 8, global step 594: 'val_roc_auc' was not in top 3\n",
      "Epoch 8, global step 629: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/michael/tpot_jupyter/AutogluonModels/ag-20251217_084812\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6882803060813532\n",
      "F1 (weighted): 0.6875998403130866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6952    0.6436    0.6684      1212\n",
      "           1     0.6826    0.7309    0.7059      1271\n",
      "\n",
      "    accuracy                         0.6883      2483\n",
      "   macro avg     0.6889    0.6872    0.6872      2483\n",
      "weighted avg     0.6887    0.6883    0.6876      2483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"new_data_train_Yelp_Fake_Review.csv\", sep=\"\\t\", engine=\"python\")\n",
    "test_df  = pd.read_csv(\"new_data_test_Yelp_Fake_Review.csv\",  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "train_df = train_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "test_df  = test_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df[\"reviewContent\"] = train_df[\"reviewContent\"].astype(str)\n",
    "test_df[\"reviewContent\"]  = test_df[\"reviewContent\"].astype(str)\n",
    "train_df[\"flagged\"] = train_df[\"flagged\"].astype(int)\n",
    "test_df[\"flagged\"]  = test_df[\"flagged\"].astype(int)\n",
    "\n",
    "print(\"Train labels:\", np.unique(train_df[\"flagged\"], return_counts=True))\n",
    "print(\"Test labels :\", np.unique(test_df[\"flagged\"],  return_counts=True))\n",
    "\n",
    "predictor = MultiModalPredictor(label=\"flagged\", problem_type=\"binary\")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_df,\n",
    "    presets=\"high_quality\",   # try \"best_quality\" if you can wait longer\n",
    "    time_limit=3600           # seconds; adjust/remove\n",
    ")\n",
    "\n",
    "y_pred = predictor.predict(test_df).astype(int).values\n",
    "y_true = test_df[\"flagged\"].values\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1 (weighted):\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "predictor.save(\"autogluon_yelp_fake_review_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df211e0-33e4-4359-ad39-5084380cd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: (array([0, 1]), array([4993, 4933]))\n",
      "Test labels : (array([0, 1]), array([1212, 1271]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260123_084141\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #8-Ubuntu SMP PREEMPT_DYNAMIC Fri Nov 14 21:44:46 UTC 2025\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.7.1+cu126\n",
      "CUDA Version:       12.6\n",
      "GPU Count:          1\n",
      "Memory Avail:       58.43 GB / 61.55 GB (94.9%)\n",
      "Disk Space Avail:   771.62 GB / 914.78 GB (84.4%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_part labels: (array([0, 1]), array([3994, 3946]))\n",
      "Val_part labels  : (array([0, 1]), array([999, 987]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name              | Type                | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 185 M  | train | 0    \n",
      "1 | validation_metric | BinaryF1Score       | 0      | train | 0    \n",
      "2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    \n",
      "--------------------------------------------------------------------------\n",
      "185 M     Trainable params\n",
      "0         Non-trainable params\n",
      "185 M     Total params\n",
      "742.365   Total estimated model params size (MB)\n",
      "318       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 31: 'val_f1' reached 0.59388 (best 0.59388), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=0-step=31.ckpt' as top 3\n",
      "Epoch 0, global step 63: 'val_f1' reached 0.59912 (best 0.59912), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=0-step=63.ckpt' as top 3\n",
      "Epoch 1, global step 94: 'val_f1' reached 0.64119 (best 0.64119), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=1-step=94.ckpt' as top 3\n",
      "Epoch 1, global step 126: 'val_f1' was not in top 3\n",
      "Epoch 2, global step 157: 'val_f1' reached 0.64634 (best 0.64634), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=2-step=157.ckpt' as top 3\n",
      "Epoch 2, global step 189: 'val_f1' reached 0.70697 (best 0.70697), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=2-step=189.ckpt' as top 3\n",
      "Epoch 3, global step 220: 'val_f1' reached 0.65792 (best 0.70697), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=3-step=220.ckpt' as top 3\n",
      "Epoch 3, global step 252: 'val_f1' reached 0.67351 (best 0.70697), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=3-step=252.ckpt' as top 3\n",
      "Epoch 4, global step 283: 'val_f1' reached 0.69590 (best 0.70697), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=4-step=283.ckpt' as top 3\n",
      "Epoch 4, global step 315: 'val_f1' reached 0.71906 (best 0.71906), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=4-step=315.ckpt' as top 3\n",
      "Epoch 5, global step 346: 'val_f1' reached 0.71857 (best 0.71906), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=5-step=346.ckpt' as top 3\n",
      "Epoch 5, global step 378: 'val_f1' was not in top 3\n",
      "Epoch 6, global step 409: 'val_f1' was not in top 3\n",
      "Epoch 6, global step 441: 'val_f1' was not in top 3\n",
      "Epoch 7, global step 472: 'val_f1' was not in top 3\n",
      "Epoch 7, global step 504: 'val_f1' was not in top 3\n",
      "Epoch 8, global step 535: 'val_f1' was not in top 3\n",
      "Epoch 8, global step 567: 'val_f1' was not in top 3\n",
      "Epoch 9, global step 598: 'val_f1' reached 0.71002 (best 0.71906), saving model to '/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141/epoch=9-step=598.ckpt' as top 3\n",
      "Epoch 9, global step 630: 'val_f1' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/michael/tpot_jupyter/AutogluonModels/ag-20260123_084141\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold on validation: 0.340 (F1=0.7310)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/michael/tpot_jupyter/miniconda3/envs/ag_env/lib/python3.10/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Default threshold (0.5 / model default) ---\n",
      "Accuracy: 0.6701570680628273\n",
      "F1      : 0.7071862710046478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7053    0.5569    0.6224      1212\n",
      "           1     0.6481    0.7781    0.7072      1271\n",
      "\n",
      "    accuracy                         0.6702      2483\n",
      "   macro avg     0.6767    0.6675    0.6648      2483\n",
      "weighted avg     0.6760    0.6702    0.6658      2483\n",
      "\n",
      "\n",
      "--- Tuned threshold ---\n",
      "Accuracy: 0.6641159887233186\n",
      "F1      : 0.7229235880398671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7540    0.4629    0.5736      1212\n",
      "           1     0.6256    0.8560    0.7229      1271\n",
      "\n",
      "    accuracy                         0.6641      2483\n",
      "   macro avg     0.6898    0.6594    0.6483      2483\n",
      "weighted avg     0.6883    0.6641    0.6500      2483\n",
      "\n",
      "\n",
      "Saved: autogluon_yelp_fake_review_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # force GPU 0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Read TRAIN / TEST (TSV)\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"new_data_train_Yelp_Fake_Review.csv\", sep=\"\\t\", engine=\"python\")\n",
    "test_df  = pd.read_csv(\"new_data_test_Yelp_Fake_Review.csv\",  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "train_df = train_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "test_df  = test_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df[\"reviewContent\"] = train_df[\"reviewContent\"].astype(str)\n",
    "test_df[\"reviewContent\"]  = test_df[\"reviewContent\"].astype(str)\n",
    "\n",
    "train_df[\"flagged\"] = train_df[\"flagged\"].astype(int)\n",
    "test_df[\"flagged\"]  = test_df[\"flagged\"].astype(int)\n",
    "\n",
    "print(\"Train labels:\", np.unique(train_df[\"flagged\"], return_counts=True))\n",
    "print(\"Test labels :\", np.unique(test_df[\"flagged\"],  return_counts=True))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Light, safe text cleaning\n",
    "#    (donâ€™t over-clean for transformers)\n",
    "# -----------------------------\n",
    "_url_re = re.compile(r\"http\\S+|www\\.\\S+\")\n",
    "_html_re = re.compile(r\"<.*?>\")\n",
    "_space_re = re.compile(r\"\\s+\")\n",
    "_repeat_re = re.compile(r\"(.)\\1{3,}\")  # loooove -> loove (soften long repeats)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = _html_re.sub(\" \", s)\n",
    "    s = _url_re.sub(\" URL \", s)\n",
    "    s = _repeat_re.sub(r\"\\1\\1\", s)\n",
    "    s = _space_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "train_df[\"reviewContent_clean\"] = train_df[\"reviewContent\"].map(clean_text)\n",
    "test_df[\"reviewContent_clean\"]  = test_df[\"reviewContent\"].map(clean_text)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Extra features (often boosts accuracy/F1)\n",
    "#    AutoGluon can use multiple columns (text + numeric)\n",
    "# -----------------------------\n",
    "def add_text_features(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    text = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "    df[\"char_len\"] = text.str.len()\n",
    "    df[\"word_count\"] = text.str.split().map(len)\n",
    "\n",
    "    df[\"exclaim_count\"] = text.str.count(\"!\")\n",
    "    df[\"question_count\"] = text.str.count(r\"\\?\")\n",
    "    df[\"upper_count\"] = text.str.count(r\"[A-Z]\")\n",
    "    df[\"digit_count\"] = text.str.count(r\"\\d\")\n",
    "\n",
    "    # ratio-ish features (avoid division by zero)\n",
    "    df[\"upper_ratio\"] = df[\"upper_count\"] / (df[\"char_len\"] + 1)\n",
    "    df[\"digit_ratio\"] = df[\"digit_count\"] / (df[\"char_len\"] + 1)\n",
    "\n",
    "    # simple â€œspammyâ€ cue: many repeated punctuation\n",
    "    df[\"multi_exclaim\"] = text.str.contains(r\"!!+\").astype(int)\n",
    "    df[\"multi_question\"] = text.str.contains(r\"\\?\\?+\").astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = add_text_features(train_df, \"reviewContent_clean\")\n",
    "test_df  = add_text_features(test_df,  \"reviewContent_clean\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Train/valid split from TRAIN (for threshold tuning)\n",
    "# -----------------------------\n",
    "train_part, val_part = train_test_split(\n",
    "    train_df[[\"reviewContent_clean\", \"char_len\", \"word_count\", \"exclaim_count\", \"question_count\",\n",
    "              \"upper_ratio\", \"digit_ratio\", \"multi_exclaim\", \"multi_question\", \"flagged\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"flagged\"]\n",
    ")\n",
    "\n",
    "print(\"Train_part labels:\", np.unique(train_part[\"flagged\"], return_counts=True))\n",
    "print(\"Val_part labels  :\", np.unique(val_part[\"flagged\"], return_counts=True))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Train AutoGluon\n",
    "#    - Use eval_metric='f1' for imbalanced datasets\n",
    "#    - presets='best_quality' for better accuracy (slower)\n",
    "# -----------------------------\n",
    "predictor = MultiModalPredictor(\n",
    "    label=\"flagged\",\n",
    "    problem_type=\"binary\",\n",
    "    eval_metric=\"f1\"\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_part,\n",
    "    tuning_data=val_part,     # explicit validation for better selection\n",
    "    presets=\"best_quality\",   # change to \"high_quality\" if too slow\n",
    "    time_limit=3600           # seconds; increase for better results (e.g., 7200)\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Optional: threshold tuning (often improves F1 a lot)\n",
    "# -----------------------------\n",
    "val_proba = predictor.predict_proba(val_part)  # dataframe with columns [0, 1] usually\n",
    "# get probability of class 1\n",
    "if isinstance(val_proba, pd.DataFrame):\n",
    "    p1 = val_proba[1].values if 1 in val_proba.columns else val_proba.iloc[:, -1].values\n",
    "else:\n",
    "    p1 = np.array(val_proba)\n",
    "\n",
    "y_val = val_part[\"flagged\"].values\n",
    "\n",
    "best_thr, best_f1 = 0.5, -1\n",
    "for thr in np.linspace(0.1, 0.9, 81):\n",
    "    pred_thr = (p1 >= thr).astype(int)\n",
    "    f1 = f1_score(y_val, pred_thr)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thr = f1, thr\n",
    "\n",
    "print(f\"Best threshold on validation: {best_thr:.3f} (F1={best_f1:.4f})\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Final evaluation on TEST set\n",
    "# -----------------------------\n",
    "test_data = test_df[[\"reviewContent_clean\", \"char_len\", \"word_count\", \"exclaim_count\", \"question_count\",\n",
    "                     \"upper_ratio\", \"digit_ratio\", \"multi_exclaim\", \"multi_question\", \"flagged\"]]\n",
    "\n",
    "test_proba = predictor.predict_proba(test_data)\n",
    "if isinstance(test_proba, pd.DataFrame):\n",
    "    p1_test = test_proba[1].values if 1 in test_proba.columns else test_proba.iloc[:, -1].values\n",
    "else:\n",
    "    p1_test = np.array(test_proba)\n",
    "\n",
    "y_true = test_data[\"flagged\"].values\n",
    "y_pred_default = predictor.predict(test_data).astype(int).values\n",
    "y_pred_thr = (p1_test >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\n--- Default threshold (0.5 / model default) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred_default))\n",
    "print(\"F1      :\", f1_score(y_true, y_pred_default))\n",
    "print(classification_report(y_true, y_pred_default, digits=4))\n",
    "\n",
    "print(\"\\n--- Tuned threshold ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred_thr))\n",
    "print(\"F1      :\", f1_score(y_true, y_pred_thr))\n",
    "print(classification_report(y_true, y_pred_thr, digits=4))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Save model\n",
    "# -----------------------------\n",
    "predictor.save(\"autogluon_yelp_fake_review_model\")\n",
    "print(\"\\nSaved: autogluon_yelp_fake_review_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f34e2a3-eddb-4432-9823-cb4f1418a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: /home/michael/tpot_jupyter/autogluon_yelp_fake_review_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "predictor = MultiModalPredictor.load(\"autogluon_yelp_fake_review_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d969db-daa0-4696-b36b-2a23be2273a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<autogluon.multimodal.predictor.MultiModalPredictor object at 0x7522fbf008e0>\n"
     ]
    }
   ],
   "source": [
    "print(predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca16e886-6a16-484d-9d77-c68f0f221093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_f1': 0.6734902858734131, 'training_time': 2300.376913547516}\n"
     ]
    }
   ],
   "source": [
    "summary = predictor.fit_summary()\n",
    "print(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e13d4a-afa4-4013-b7c1-a23dda208335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: /home/michael/tpot_jupyter/autogluon_yelp_fake_review_model/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_f1': 0.6734902858734131, 'training_time': 2300.376913547516}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "loaded = MultiModalPredictor.load(\"autogluon_yelp_fake_review_model\")\n",
    "print(loaded.fit_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ebfbeb-05c6-4795-bea0-8ac1452a0101",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiModalPredictor' object has no attribute '_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mmodel)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiModalPredictor' object has no attribute '_config'"
     ]
    }
   ],
   "source": [
    "print(loaded._config.data)\n",
    "print(loaded._config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27297549-2333-4ca6-8381-ac7814305b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiModalPredictor' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_encoder)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiModalPredictor' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "text_encoder = model.text\n",
    "print(text_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bd9f2-5fe5-4d66-98d1-cfd8202ce2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.numerical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bc419-d5ad-48c4-b53a-02cea121a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa45ec7-ce72-44ab-a3a0-7ed4c166470d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiModalPredictor' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiModalPredictor' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "print(model.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026bb79-3dc1-4df7-826d-181b7a52caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "predictor.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ag_env)",
   "language": "python",
   "name": "ag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
