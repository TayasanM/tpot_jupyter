{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c4935f-4bd3-4b38-8107-4bf9f5f9fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: (array([0, 1]), array([4993, 4933]))\n",
      "Test labels : (array([0, 1]), array([1212, 1271]))\n",
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.17-internal\" 2025-10-21; OpenJDK Runtime Environment (build 17.0.17-internal+0-adhoc..src); OpenJDK 64-Bit Server VM (build 17.0.17-internal+0-adhoc..src, mixed mode, sharing)\n",
      "  Starting server from /home/michael/tpot_jupyter/miniconda3/envs/h2o_env/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpoc1qaq7a\n",
      "  JVM stdout: /tmp/tmpoc1qaq7a/h2o_michael_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpoc1qaq7a/h2o_michael_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>00 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Rome</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_michael_9wlyyc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>8 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.19 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         00 secs\n",
       "H2O_cluster_timezone:       Europe/Rome\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_michael_9wlyyc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    8 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.19 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "11:49:44.544: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "11:49:48.744: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "11:49:55.223: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "11:50:02.564: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "11:50:06.155: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "11:50:33.181: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "11:50:39.801: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "11:50:46.238: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "11:50:56.876: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "11:50:58.275: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "███\n",
      "11:51:29.110: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "\n",
      "11:51:34.726: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█████████████████████████████████████████████\n",
      "12:00:13.571: _train param, Dropping unused columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "12:00:14.687: _train param, Dropping unused columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "███| (done) 100%\n",
      "model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse       mse\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20251219_114944     0.733971   0.603737  0.71128                 0.355216  0.456557  0.208444\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_1_20251219_114944  0.733488   0.604353  0.713203                0.352091  0.456846  0.208708\n",
      "GLM_1_AutoML_1_20251219_114944                           0.725763   0.610085  0.707962                0.366344  0.459677  0.211303\n",
      "GBM_1_AutoML_1_20251219_114944                           0.702983   0.626718  0.675031                0.385142  0.467486  0.218543\n",
      "GBM_2_AutoML_1_20251219_114944                           0.697776   0.629995  0.668579                0.385956  0.469087  0.220043\n",
      "GBM_5_AutoML_1_20251219_114944                           0.694334   0.63266   0.664025                0.383938  0.470307  0.221188\n",
      "GBM_grid_1_AutoML_1_20251219_114944_model_1              0.689857   0.635983  0.65612                 0.380179  0.471786  0.222582\n",
      "GBM_4_AutoML_1_20251219_114944                           0.68838    0.638244  0.659473                0.384972  0.472861  0.223597\n",
      "GBM_3_AutoML_1_20251219_114944                           0.6856     0.638976  0.654953                0.385571  0.473258  0.223973\n",
      "GBM_grid_1_AutoML_1_20251219_114944_model_2              0.680712   0.645181  0.64978                 0.406033  0.475907  0.226488\n",
      "[10 rows x 7 columns]\n",
      "\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "\n",
      "Accuracy: 0.666532420459122\n",
      "F1: 0.7234468937875751\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7526    0.4719    0.5801      1212\n",
      "           1     0.6286    0.8521    0.7234      1271\n",
      "\n",
      "    accuracy                         0.6665      2483\n",
      "   macro avg     0.6906    0.6620    0.6518      2483\n",
      "weighted avg     0.6891    0.6665    0.6535      2483\n",
      "\n",
      "\n",
      "✅ Saved leader model to: /home/michael/tpot_jupyter/h2o_models/StackedEnsemble_AllModels_1_AutoML_1_20251219_114944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/tpot_jupyter/miniconda3/envs/h2o_env/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Read TRAIN / TEST (TSV)\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"new_data_train_Yelp_Fake_Review.csv\", sep=\"\\t\", engine=\"python\")\n",
    "test_df  = pd.read_csv(\"new_data_test_Yelp_Fake_Review.csv\",  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "train_df = train_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "test_df  = test_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df[\"reviewContent\"] = train_df[\"reviewContent\"].astype(str)\n",
    "test_df[\"reviewContent\"]  = test_df[\"reviewContent\"].astype(str)\n",
    "train_df[\"flagged\"] = train_df[\"flagged\"].astype(int)\n",
    "test_df[\"flagged\"]  = test_df[\"flagged\"].astype(int)\n",
    "\n",
    "print(\"Train labels:\", np.unique(train_df[\"flagged\"], return_counts=True))\n",
    "print(\"Test labels :\", np.unique(test_df[\"flagged\"],  return_counts=True))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Light text cleaning\n",
    "# -----------------------------\n",
    "_url_re = re.compile(r\"http\\S+|www\\.\\S+\")\n",
    "_html_re = re.compile(r\"<.*?>\")\n",
    "_space_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = _html_re.sub(\" \", s)\n",
    "    s = _url_re.sub(\" URL \", s)\n",
    "    s = _space_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "train_df[\"text\"] = train_df[\"reviewContent\"].map(clean_text)\n",
    "test_df[\"text\"]  = test_df[\"reviewContent\"].map(clean_text)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Structured feature engineering\n",
    "# -----------------------------\n",
    "def add_text_features(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    text = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "    df[\"char_len\"] = text.str.len()\n",
    "    df[\"word_count\"] = text.str.split().map(len)\n",
    "\n",
    "    df[\"exclaim_count\"] = text.str.count(\"!\")\n",
    "    df[\"question_count\"] = text.str.count(r\"\\?\")\n",
    "    df[\"upper_count\"] = text.str.count(r\"[A-Z]\")\n",
    "    df[\"digit_count\"] = text.str.count(r\"\\d\")\n",
    "\n",
    "    df[\"upper_ratio\"] = df[\"upper_count\"] / (df[\"char_len\"] + 1)\n",
    "    df[\"digit_ratio\"] = df[\"digit_count\"] / (df[\"char_len\"] + 1)\n",
    "\n",
    "    df[\"multi_exclaim\"] = text.str.contains(r\"!!+\").astype(int)\n",
    "    df[\"multi_question\"] = text.str.contains(r\"\\?\\?+\").astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = add_text_features(train_df, \"text\")\n",
    "test_df  = add_text_features(test_df,  \"text\")\n",
    "\n",
    "struct_cols = [\n",
    "    \"char_len\",\"word_count\",\"exclaim_count\",\"question_count\",\n",
    "    \"upper_ratio\",\"digit_ratio\",\"multi_exclaim\",\"multi_question\"\n",
    "]\n",
    "\n",
    "for c in struct_cols:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").fillna(0)\n",
    "    test_df[c]  = pd.to_numeric(test_df[c],  errors=\"coerce\").fillna(0)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Text -> TF-IDF -> SVD embeddings (multimodal fusion via features)\n",
    "# -----------------------------\n",
    "# TF-IDF (char ngrams often strong for spam/fake)\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=2,\n",
    "    max_features=200000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(train_df[\"text\"])\n",
    "X_tfidf_test  = tfidf.transform(test_df[\"text\"])\n",
    "\n",
    "# Reduce dimensionality for H2O (dense numeric matrix)\n",
    "svd_dim = 300  # try 100/300/500\n",
    "svd = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "\n",
    "X_svd_train = svd.fit_transform(X_tfidf_train)\n",
    "X_svd_test  = svd.transform(X_tfidf_test)\n",
    "\n",
    "svd_cols = [f\"svd_{i}\" for i in range(svd_dim)]\n",
    "svd_train_df = pd.DataFrame(X_svd_train, columns=svd_cols)\n",
    "svd_test_df  = pd.DataFrame(X_svd_test,  columns=svd_cols)\n",
    "\n",
    "# Combine: [structured] + [svd embeddings] + label\n",
    "train_final = pd.concat([train_df[struct_cols].reset_index(drop=True),\n",
    "                         svd_train_df.reset_index(drop=True),\n",
    "                         train_df[[\"flagged\"]].reset_index(drop=True)], axis=1)\n",
    "\n",
    "test_final  = pd.concat([test_df[struct_cols].reset_index(drop=True),\n",
    "                         svd_test_df.reset_index(drop=True),\n",
    "                         test_df[[\"flagged\"]].reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) H2O AutoML training\n",
    "# -----------------------------\n",
    "h2o.init(max_mem_size=\"8G\", nthreads=-1)  # adjust memory if needed :contentReference[oaicite:3]{index=3}\n",
    "\n",
    "hf_train = h2o.H2OFrame(train_final)\n",
    "hf_test  = h2o.H2OFrame(test_final)\n",
    "\n",
    "# Make label categorical for classification\n",
    "hf_train[\"flagged\"] = hf_train[\"flagged\"].asfactor()\n",
    "hf_test[\"flagged\"]  = hf_test[\"flagged\"].asfactor()\n",
    "\n",
    "x_cols = [c for c in hf_train.columns if c != \"flagged\"]\n",
    "y_col = \"flagged\"\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_models=20,          # or use max_runtime_secs\n",
    "    seed=42,\n",
    "    sort_metric=\"AUC\",      # good default for binary\n",
    "    nfolds=5\n",
    ")\n",
    "\n",
    "aml.train(x=x_cols, y=y_col, training_frame=hf_train)\n",
    "\n",
    "print(aml.leaderboard.head())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Evaluate on test set\n",
    "# -----------------------------\n",
    "pred = aml.leader.predict(hf_test)   # returns h2o frame with \"predict\", \"p0\", \"p1\"\n",
    "pred_df = pred.as_data_frame()\n",
    "\n",
    "y_pred = (pred_df[\"predict\"].astype(str) == \"1\").astype(int).values\n",
    "y_true = test_final[\"flagged\"].astype(int).values\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# (Optional) Save leader model\n",
    "model_path = h2o.save_model(aml.leader, path=\"h2o_models\", force=True)\n",
    "print(\"\\n✅ Saved leader model to:\", model_path)\n",
    "\n",
    "# shutdown optional\n",
    "# h2o.shutdown(prompt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72db8984-5a81-4370-9e55-ebf6bf48d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Text-only H2O AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba7ccb-bcae-42eb-9bcf-fa7f2791c788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a586478c-6d7c-4c85-9d6e-06934a6a3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: (array([0, 1]), array([4993, 4933]))\n",
      "Test labels : (array([0, 1]), array([1212, 1271]))\n",
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>26 mins 24 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Rome</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_michael_9wlyyc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.806 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.19 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         26 mins 24 secs\n",
       "H2O_cluster_timezone:       Europe/Rome\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_michael_9wlyyc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.806 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.19 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse       mse\n",
      "StackedEnsemble_AllModels_1_AutoML_2_20251219_121607     0.73236    0.605165  0.71174                 0.353016  0.457239  0.209068\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_2_20251219_121607  0.731645   0.605793  0.712376                0.364793  0.457572  0.209372\n",
      "GLM_1_AutoML_2_20251219_121607                           0.726277   0.609756  0.708473                0.352727  0.459524  0.211162\n",
      "GBM_1_AutoML_2_20251219_121607                           0.698138   0.630039  0.671533                0.389657  0.469082  0.220038\n",
      "GBM_3_AutoML_2_20251219_121607                           0.690228   0.636253  0.662995                0.395205  0.471962  0.222748\n",
      "GBM_5_AutoML_2_20251219_121607                           0.688843   0.635828  0.662684                0.393783  0.471885  0.222676\n",
      "GBM_2_AutoML_2_20251219_121607                           0.688355   0.636793  0.659237                0.393008  0.472271  0.22304\n",
      "GBM_4_AutoML_2_20251219_121607                           0.682563   0.64341   0.651131                0.394689  0.475001  0.225626\n",
      "GBM_grid_1_AutoML_2_20251219_121607_model_2              0.679803   0.645115  0.652311                0.394139  0.476095  0.226666\n",
      "GBM_grid_1_AutoML_2_20251219_121607_model_1              0.679501   0.642355  0.649026                0.400763  0.474944  0.225572\n",
      "[10 rows x 7 columns]\n",
      "\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "\n",
      "Accuracy: 0.6689488521949255\n",
      "F1: 0.7221095334685599\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7450    0.4893    0.5906      1212\n",
      "           1     0.6331    0.8403    0.7221      1271\n",
      "\n",
      "    accuracy                         0.6689      2483\n",
      "   macro avg     0.6890    0.6648    0.6564      2483\n",
      "weighted avg     0.6877    0.6689    0.6579      2483\n",
      "\n",
      "\n",
      "✅ Saved leader model to: /home/michael/tpot_jupyter/h2o_models_text_only/StackedEnsemble_AllModels_1_AutoML_2_20251219_121607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/tpot_jupyter/miniconda3/envs/h2o_env/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# -----------------------------\n",
    "# A) Read TRAIN / TEST (TSV)\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"new_data_train_Yelp_Fake_Review.csv\", sep=\"\\t\", engine=\"python\")\n",
    "test_df  = pd.read_csv(\"new_data_test_Yelp_Fake_Review.csv\",  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "train_df = train_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "test_df  = test_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df[\"reviewContent\"] = train_df[\"reviewContent\"].astype(str)\n",
    "test_df[\"reviewContent\"]  = test_df[\"reviewContent\"].astype(str)\n",
    "train_df[\"flagged\"] = train_df[\"flagged\"].astype(int)\n",
    "test_df[\"flagged\"]  = test_df[\"flagged\"].astype(int)\n",
    "\n",
    "print(\"Train labels:\", np.unique(train_df[\"flagged\"], return_counts=True))\n",
    "print(\"Test labels :\", np.unique(test_df[\"flagged\"],  return_counts=True))\n",
    "\n",
    "# -----------------------------\n",
    "# B) Clean text\n",
    "# -----------------------------\n",
    "_url_re = re.compile(r\"http\\S+|www\\.\\S+\")\n",
    "_html_re = re.compile(r\"<.*?>\")\n",
    "_space_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = _html_re.sub(\" \", s)\n",
    "    s = _url_re.sub(\" URL \", s)\n",
    "    s = _space_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "train_text = train_df[\"reviewContent\"].map(clean_text)\n",
    "test_text  = test_df[\"reviewContent\"].map(clean_text)\n",
    "\n",
    "# -----------------------------\n",
    "# C) TF-IDF -> SVD (text embeddings)\n",
    "# -----------------------------\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=2,\n",
    "    max_features=200000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(train_text)\n",
    "X_tfidf_test  = tfidf.transform(test_text)\n",
    "\n",
    "svd_dim = 300  # try 100, 300, 500\n",
    "svd = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "\n",
    "X_svd_train = svd.fit_transform(X_tfidf_train)\n",
    "X_svd_test  = svd.transform(X_tfidf_test)\n",
    "\n",
    "svd_cols = [f\"svd_{i}\" for i in range(svd_dim)]\n",
    "train_final = pd.DataFrame(X_svd_train, columns=svd_cols)\n",
    "test_final  = pd.DataFrame(X_svd_test,  columns=svd_cols)\n",
    "\n",
    "train_final[\"flagged\"] = train_df[\"flagged\"].values\n",
    "test_final[\"flagged\"]  = test_df[\"flagged\"].values\n",
    "\n",
    "# -----------------------------\n",
    "# D) H2O AutoML\n",
    "# -----------------------------\n",
    "h2o.init(max_mem_size=\"8G\", nthreads=-1)\n",
    "\n",
    "hf_train = h2o.H2OFrame(train_final)\n",
    "hf_test  = h2o.H2OFrame(test_final)\n",
    "\n",
    "hf_train[\"flagged\"] = hf_train[\"flagged\"].asfactor()\n",
    "hf_test[\"flagged\"]  = hf_test[\"flagged\"].asfactor()\n",
    "\n",
    "x_cols = [c for c in hf_train.columns if c != \"flagged\"]\n",
    "y_col = \"flagged\"\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_models=20,\n",
    "    seed=42,\n",
    "    sort_metric=\"AUC\",\n",
    "    nfolds=5\n",
    ")\n",
    "aml.train(x=x_cols, y=y_col, training_frame=hf_train)\n",
    "\n",
    "print(aml.leaderboard.head())\n",
    "\n",
    "# -----------------------------\n",
    "# E) Evaluate\n",
    "# -----------------------------\n",
    "pred = aml.leader.predict(hf_test).as_data_frame()\n",
    "y_pred = (pred[\"predict\"].astype(str) == \"1\").astype(int).values\n",
    "y_true = test_final[\"flagged\"].astype(int).values\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Save model\n",
    "model_path = h2o.save_model(aml.leader, path=\"h2o_models_text_only\", force=True)\n",
    "print(\"\\n✅ Saved leader model to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc5b26-59b9-4f2e-ac0b-9593df170ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: (array([0, 1]), array([4993, 4933]))\n",
      "Test labels : (array([0, 1]), array([1212, 1271]))\n",
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>3 days 2 hours 5 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Rome</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>27 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_michael_9wlyyc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.625 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.19 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         3 days 2 hours 5 mins\n",
       "H2O_cluster_timezone:       Europe/Rome\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    27 days\n",
       "H2O_cluster_name:           H2O_from_python_michael_9wlyyc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.625 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.19 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "13:55:12.246: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "13:55:15.348: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "13:55:20.326: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "13:55:27.793: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "13:55:31.468: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "███\n",
      "13:55:57.75: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "\n",
      "13:56:03.635: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "█\n",
      "13:56:10.418: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "██\n",
      "13:56:21.529: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "13:56:23.112: _train param, Dropping bad and constant columns: [question_count, exclaim_count, upper_ratio, multi_exclaim, multi_question]\n",
      "\n",
      "███"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# -----------------------------\n",
    "# A) Read TRAIN / TEST (TSV)\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"new_data_train_Yelp_Fake_Review.csv\", sep=\"\\t\", engine=\"python\")\n",
    "test_df  = pd.read_csv(\"new_data_test_Yelp_Fake_Review.csv\",  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "train_df = train_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "test_df  = test_df[[\"reviewContent\", \"flagged\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df[\"reviewContent\"] = train_df[\"reviewContent\"].astype(str)\n",
    "test_df[\"reviewContent\"]  = test_df[\"reviewContent\"].astype(str)\n",
    "train_df[\"flagged\"] = train_df[\"flagged\"].astype(int)\n",
    "test_df[\"flagged\"]  = test_df[\"flagged\"].astype(int)\n",
    "\n",
    "print(\"Train labels:\", np.unique(train_df[\"flagged\"], return_counts=True))\n",
    "print(\"Test labels :\", np.unique(test_df[\"flagged\"],  return_counts=True))\n",
    "\n",
    "# -----------------------------\n",
    "# B) Clean text\n",
    "# -----------------------------\n",
    "_url_re = re.compile(r\"http\\S+|www\\.\\S+\")\n",
    "_html_re = re.compile(r\"<.*?>\")\n",
    "_space_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    s = _html_re.sub(\" \", s)\n",
    "    s = _url_re.sub(\" URL \", s)\n",
    "    s = _space_re.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "train_df[\"text\"] = train_df[\"reviewContent\"].map(clean_text)\n",
    "test_df[\"text\"]  = test_df[\"reviewContent\"].map(clean_text)\n",
    "\n",
    "# -----------------------------\n",
    "# C) Structured features\n",
    "# -----------------------------\n",
    "def add_text_features(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    text = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "    df[\"char_len\"] = text.str.len()\n",
    "    df[\"word_count\"] = text.str.split().map(len)\n",
    "    df[\"exclaim_count\"] = text.str.count(\"!\")\n",
    "    df[\"question_count\"] = text.str.count(r\"\\?\")\n",
    "    df[\"upper_count\"] = text.str.count(r\"[A-Z]\")\n",
    "    df[\"digit_count\"] = text.str.count(r\"\\d\")\n",
    "\n",
    "    df[\"upper_ratio\"] = df[\"upper_count\"] / (df[\"char_len\"] + 1)\n",
    "    df[\"digit_ratio\"] = df[\"digit_count\"] / (df[\"char_len\"] + 1)\n",
    "\n",
    "    df[\"multi_exclaim\"] = text.str.contains(r\"!!+\").astype(int)\n",
    "    df[\"multi_question\"] = text.str.contains(r\"\\?\\?+\").astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = add_text_features(train_df, \"text\")\n",
    "test_df  = add_text_features(test_df,  \"text\")\n",
    "\n",
    "struct_cols = [\n",
    "    \"char_len\",\"word_count\",\"exclaim_count\",\"question_count\",\n",
    "    \"upper_ratio\",\"digit_ratio\",\"multi_exclaim\",\"multi_question\"\n",
    "]\n",
    "\n",
    "for c in struct_cols:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").fillna(0)\n",
    "    test_df[c]  = pd.to_numeric(test_df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# D) TF-IDF -> SVD embeddings\n",
    "# -----------------------------\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=2,\n",
    "    max_features=200000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(train_df[\"text\"])\n",
    "X_tfidf_test  = tfidf.transform(test_df[\"text\"])\n",
    "\n",
    "svd_dim = 300\n",
    "svd = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "\n",
    "X_svd_train = svd.fit_transform(X_tfidf_train)\n",
    "X_svd_test  = svd.transform(X_tfidf_test)\n",
    "\n",
    "svd_cols = [f\"svd_{i}\" for i in range(svd_dim)]\n",
    "svd_train_df = pd.DataFrame(X_svd_train, columns=svd_cols)\n",
    "svd_test_df  = pd.DataFrame(X_svd_test,  columns=svd_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# E) Combine (multimodal fusion via features)\n",
    "# -----------------------------\n",
    "train_final = pd.concat(\n",
    "    [train_df[struct_cols].reset_index(drop=True),\n",
    "     svd_train_df.reset_index(drop=True),\n",
    "     train_df[[\"flagged\"]].reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "test_final = pd.concat(\n",
    "    [test_df[struct_cols].reset_index(drop=True),\n",
    "     svd_test_df.reset_index(drop=True),\n",
    "     test_df[[\"flagged\"]].reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# F) H2O AutoML\n",
    "# -----------------------------\n",
    "h2o.init(max_mem_size=\"8G\", nthreads=-1)\n",
    "\n",
    "hf_train = h2o.H2OFrame(train_final)\n",
    "hf_test  = h2o.H2OFrame(test_final)\n",
    "\n",
    "hf_train[\"flagged\"] = hf_train[\"flagged\"].asfactor()\n",
    "hf_test[\"flagged\"]  = hf_test[\"flagged\"].asfactor()\n",
    "\n",
    "x_cols = [c for c in hf_train.columns if c != \"flagged\"]\n",
    "y_col = \"flagged\"\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_models=20,\n",
    "    seed=42,\n",
    "    sort_metric=\"AUC\",\n",
    "    nfolds=5\n",
    ")\n",
    "aml.train(x=x_cols, y=y_col, training_frame=hf_train)\n",
    "\n",
    "print(aml.leaderboard.head())\n",
    "\n",
    "# -----------------------------\n",
    "# G) Evaluate\n",
    "# -----------------------------\n",
    "pred = aml.leader.predict(hf_test).as_data_frame()\n",
    "y_pred = (pred[\"predict\"].astype(str) == \"1\").astype(int).values\n",
    "y_true = test_final[\"flagged\"].astype(int).values\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Save model\n",
    "model_path = h2o.save_model(aml.leader, path=\"h2o_models_multimodal\", force=True)\n",
    "print(\"\\n✅ Saved leader model to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b151af05-f829-46a0-ab52-f02bcbf89cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m leader \u001b[38;5;241m=\u001b[39m \u001b[43maml\u001b[49m\u001b[38;5;241m.\u001b[39mleader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeader:\u001b[39m\u001b[38;5;124m\"\u001b[39m, leader\u001b[38;5;241m.\u001b[39mmodel_id)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgo:\u001b[39m\u001b[38;5;124m\"\u001b[39m, leader\u001b[38;5;241m.\u001b[39malgo)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aml' is not defined"
     ]
    }
   ],
   "source": [
    "leader = aml.leader\n",
    "print(\"Leader:\", leader.model_id)\n",
    "print(\"Algo:\", leader.algo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72c6230-76f3-4c44-ac63-457e96d84002",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m leader \u001b[38;5;241m=\u001b[39m \u001b[43maml\u001b[49m\u001b[38;5;241m.\u001b[39mleader\n\u001b[1;32m      4\u001b[0m base_models \u001b[38;5;241m=\u001b[39m leader\u001b[38;5;241m.\u001b[39mbase_models\n\u001b[1;32m      5\u001b[0m metalearner \u001b[38;5;241m=\u001b[39m leader\u001b[38;5;241m.\u001b[39mmetalearner()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aml' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "leader = aml.leader\n",
    "base_models = leader.base_models\n",
    "metalearner = leader.metalearner()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Leader box\n",
    "plt.text(0.5, 0.9, f\"StackedEnsemble (Leader)\\n{leader.model_id}\",\n",
    "         ha=\"center\", va=\"center\", bbox=dict(boxstyle=\"round\", pad=0.5))\n",
    "\n",
    "# Base models\n",
    "y = 0.65\n",
    "x_start = 0.1\n",
    "x_step = 0.8 / max(1, min(len(base_models), 6))  # show first 6 if many\n",
    "shown = base_models[:6]\n",
    "\n",
    "for i, bm in enumerate(shown):\n",
    "    x = x_start + i * x_step\n",
    "    plt.text(x, y, f\"Base model\\n{bm}\",\n",
    "             ha=\"center\", va=\"center\", bbox=dict(boxstyle=\"round\", pad=0.3))\n",
    "    plt.plot([x, 0.5], [y-0.05, 0.78], linewidth=1)\n",
    "\n",
    "if len(base_models) > 6:\n",
    "    plt.text(0.5, 0.55, f\"... + {len(base_models)-6} more base models ...\",\n",
    "             ha=\"center\", va=\"center\")\n",
    "\n",
    "# Metalearner box\n",
    "plt.text(0.5, 0.35, f\"Metalearner\\n{metalearner.algo.upper()}\\n{metalearner.model_id}\",\n",
    "         ha=\"center\", va=\"center\", bbox=dict(boxstyle=\"round\", pad=0.5))\n",
    "plt.plot([0.5, 0.5], [0.78, 0.45], linewidth=2)\n",
    "\n",
    "plt.text(0.5, 0.1, \"Final Prediction (flagged 0/1)\",\n",
    "         ha=\"center\", va=\"center\", bbox=dict(boxstyle=\"round\", pad=0.4))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992ead10-caaf-4c40-b416-29c8bf853712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3e54a-45a2-4b31-aff5-bc282e7b1cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (h2o_env)",
   "language": "python",
   "name": "h2o_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
